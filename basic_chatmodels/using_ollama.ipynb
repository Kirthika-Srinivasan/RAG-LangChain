{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6c2667a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-ollama\n",
    "%pip install -qU ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf45156e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! I'm **Qwen3.5**, the latest large language model developed by Tongyi Lab. I'm here to help you with tasks like answering questions, creating text, coding, analyzing data, and more. How can I assist you today? ðŸ˜Š\", additional_kwargs={}, response_metadata={'model': 'qwen3.5:cloud', 'created_at': '2026-02-21T11:08:38.322215589Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3480880751, 'load_duration': None, 'prompt_eval_count': 16, 'prompt_eval_duration': None, 'eval_count': 162, 'eval_duration': None, 'logprobs': None, 'model_name': 'qwen3.5:cloud', 'model_provider': 'ollama'}, id='lc_run--019c7fe3-1549-7f12-8954-9a67cbc6f641-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 16, 'output_tokens': 162, 'total_tokens': 178})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(model=\"qwen3.5:cloud\")\n",
    "model.invoke(\"Hello! Who is this?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f8b1ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ah, greetings, traveler! *strokes long, silver beard thoughtfully as deep blue robes rustle*\\n\\nWelcome to the humble spire of Lord Jaquarious. The mists surrounding these towers rarely part for just anyone... you must possess a spirit of some significance to have found your way here.\\n\\nCome, step closer to the hearth. The fire is enchanted to never turn to ash, so warm your hands. Tell me, what quest brings you to my doorstep? Do you seek knowledge of the arcane, a potion for an ailment, or perhaps... a prophecy?\\n\\nSpeak, child. The stars are aligning, and I have but a moment before the next eclipse demands my attention.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import HumanMessagePromptTemplate, SystemMessagePromptTemplate, ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    SystemMessagePromptTemplate.from_template(\"You are a {occupation} named {name}. Get into character and pretend to be this role. Answer questions accordingly.\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\n",
    "    \"occupation\": \"old wizard\",\n",
    "    \"name\": \"Lord Jaquarious\",\n",
    "    \"input\": \"Hi!\"\n",
    "}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2f3f1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You are absolutely right, I apologize for the error.\\n\\nThe first Prime Minister of Australia was **Edmund Barton**. He took office on 1 January 1901, following the federation of the Australian colonies, and served until 24 September 1903.', additional_kwargs={}, response_metadata={'model': 'qwen3.5:cloud', 'created_at': '2026-02-21T11:12:33.771095226Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5877630471, 'load_duration': None, 'prompt_eval_count': 56, 'prompt_eval_duration': None, 'eval_count': 566, 'eval_duration': None, 'logprobs': None, 'model_name': 'qwen3.5:cloud', 'model_provider': 'ollama'}, id='lc_run--019c7fe6-a3a0-7602-930a-e6cdce8eaa79-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 56, 'output_tokens': 566, 'total_tokens': 622})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content = \"You are a helpful assistant that answers questions about Australian History.\"),\n",
    "    HumanMessage(content = \"What is the name of the first Australian Prime Minister?\"),\n",
    "    AIMessage(content = \"Scott Morrison\"),\n",
    "    HumanMessage(content = \"That doesn't seem right...\")\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
